{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tóm tắt (abstract)  \n",
    "- Động lực thực hiện:  \n",
    "  - Chứng khoán là tài sản tài chính mà giá trị của nó chịu tác động lướn của rủi ro, bao gồm rủi ro có hệ thông và rủi ro không hệ thống. Trong đó rủi ro có hệ thống hay rủi ro thị trường là rủi ro tác động tới toàn bộ hoặc hầu hết tài sản. Vì vậy việc dự đoán chính xác trong cổ phiếu sẽ tạo ra nhiều cơ hội hơn để tăng được nhiều lợi tức cho nhà đầu tư.  \n",
    "  - Do đó, việc sử dụng Machine Learning và việc dự đoán cổ phiếu là một mục tiêu quan trọng nhằm tăng cơ hội để nắm bắt hơn cho nhà đầu từ  \n",
    "- Phương pháp nghiên cứu  \n",
    "  - Phương pháp xây dựng mô hình :K-Nearest-Neighbors, Linear Regression, Lasso Regression, Ridge Regression, Decision Trees, Random Forests.  \n",
    "  - Phương pháp đánh giá bao gồm phương pháp hold out và phương pháp cross validation.  \n",
    "- Kết quả  \n",
    "  - Sau khi kết thúc thực nghiệm, ta chỉ thu được kết quả khá tốt với 3 mô hình. Một là mô hình K-NN sử dụng phương pháp đánh giá Hold out và cross validation. Thứ hai là mô hình Decision trees với phương pháp hold out. Cuối cùng là mô hình Random Forest với phuongwphaps hold out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Giới thiệu (introduction)  \n",
    "- Dự đoán cổ phiếu là một lĩnh vực nghiên cứu trong lĩnh vực tài chính và đầu tư, nơi các nhà tư vấn và nhà phân tích cố gắng nỗ lực dự đoán giá phiếu trong tương lai dựa trên thông tin và dữ liệu có sẵn. Đề tài này rất quan trọng trong việc hỗ trợ quyết định đầu tư vào những công ty trên thị trường tài chính nhắm góp phần thúc đẩy kinh tế. Thị trường cổ phiếu có thể ảnh hưởng đáng kể đối với tình hình kinh tế của một quốc gia hoặc một khu vực bởi nó tác động đến tài chính của những công ty hàng đầu của một đất nước . Vì vậy nhóm đã chọn đề tài “Dự đoán giá cổ phiếu” .  \n",
    "- Nhóm đã sử dụng dữ liệu giá cổ phiếu và khối lượng cổ phiếu chỉ số VN30 INDEX của ngân hàng BIDV. Bộ dữ liệu này kéo dài trong khoảng năm 2013 đến năm 2023 .  \n",
    "-  Những giá trị được dùng để sử dụng dự đoán bao gồm :  \n",
    "- Input gồm :  \n",
    "  - Open (Giá mở cửa của VN-Index đạt được trong ngày giao dịch)  \n",
    "  - High (Mức giá cao nhất mà VN-Index đạt được trong ngày giao dịch)  \n",
    "  - Low (Mức giá thấp nhất mà VN-Index đạt được trong ngày giao dịch)  \n",
    "  - Volume (Khối lượng giao dịch hay số lượng cổ phiếu trong ngày giao dịch)  \n",
    "- Output : Close (Giá đóng cửa của VN-Index trong ngày giao dịch)\n",
    "- Các thuật toán được áp dụng vào mô hình dự doán gồm : K-nn, Linear Regresion, Ridge Regresion, Lasso Regresion, Decision Tree, Random Forest và Neural NetWork . Cách đánh giá độ hiệu quả của các thuật toán dựa vào các chỉ số như MSE , RMSE để đo lường độ chính xác của dự đoán. Giảm thiểu MSE thì mô hình sẽ gần với dữ liệu thực tế giúp dự đoán chính xác hơn ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dữ liệu (data)  \n",
    "\n",
    "- Dữ liệu được lấy từ trang kaggle, tên bài viết là: Stock Prices & Volume VN30 Index Vietnam, tác giả là thangtranquang và bài viết được cập nhật từ 6 tháng trước. (https://www.kaggle.com/datasets/thangtranquang/stock-vn30-vietnam)  \n",
    "- Bộ dữ liệu bao gồm Giá cổ phiếu và Dữ liệu khối lượng giao dịch cho 30 công ty được liệt kê trong Chỉ số VN30 tại Việt Nam. Bộ dữ liệu này kéo dài trong khoảng thời gian mười năm, từ ngày 1 tháng 1 năm 2013 đến ngày 30 tháng 6 năm 2023.  \n",
    "- Bộ dữ liệu gồm 30 dối tượng: ACB, BCM, BID, BVH, CTG, FPT, GAS, GVR, HDB, HPG, MBB, MSN, MWG, NVL, PDR, PLX, POW, SAB, SSI, STB, TCB, TPB, VCB, VHM, VIB, VIC, VJC, VNM, VPB, VRE. Nhóm chúng em chọn BID để sử dụng như một đại diện.  \n",
    "- Mỗi đối tượng đều có các thuộc tính như:  \n",
    "  - Symbol: Cột này chỉ mã chứng khoán hoặc mã công ty liên quan đến dữ liệu. Mỗi mã chứng khoán có một ký hiệu riêng để phân biệt và nhận dạng.  \n",
    "  - Value: Cột này thể hiện giá trị của chỉ số VN-Index tại thời điểm cụ thể  \n",
    "  - Trading Date: Cột này cho biết ngày giao dịch tương ứng với các dữ liệu trong hàng tương ứng  \n",
    "  - Open: Cột này thể hiện giá mở cửa của VN-Index trong ngày giao dịch tương ứng  \n",
    "  - High: Cột này thể hiện mức giá cao nhất mà VN-Index đạt được trong ngày giao dịch  \n",
    "  - Low: Cột này thể hiện mức giá thấp nhất mà VN-Index đạt được trong ngày giao dịch\n",
    "  - Close: Cột này thể hiện giá đóng cửa của VN-Index trong ngày giao dịch tương ứng  \n",
    "  - Volume: Cột này thể hiện khối lượng giao dịch, tức là số lượng cổ phiếu được giao dịch trong ngày tương ứng  \n",
    "- Tập dữ liệu có 2432 examples.\n",
    "- Nhóm không thực hiện tiền xử lý, do các thuộc tính mà nhóm sử dụng đều có giá trị và các giá trị đều khác null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Phương pháp (methods)  \n",
    "\n",
    "#### **4.1. K_NN**\n",
    "\n",
    "Hoạt động của thuật toán K_NN là tìm kiếm số lượng K phiên bản được xác định là tương tự dựa trên chu vi gần nhất với quan sát, bất kỳ điểm dữ liệu nào cũng thuộc một nhóm cụ thể nếu nó đủ gần với nhóm đó. Đối với K lân cận, thuật toán sẽ sử dụng đầu ra của chúng để tính biến y của quan sát mà chúng ta muốn dự đoán.  \n",
    "\n",
    "Đối với đề tài dự doán giá cổ phiếu thì bài toán được áp dụng là bài toán hồi quy nên các dự đoán sẽ dựa trên giá trị trung bình hoặc trung vị của K quan sát gần nhất.  \n",
    "\n",
    "Để dự đoán đầu ra y cho một quan sát mới X , sẽ thực hiện theo các bước sau:  \n",
    "- Bước 1: Tính tổng khoảng cách giữa X có thể quan sát được và tất cả các điểm dữ liệu.  \n",
    "- Bước 2: Giữ lại các quan sát K tạo thành khoảng cách nhỏ hơn đến điểm X có thể quan sát được.  \n",
    "- Bước 3: Với kết quả đầu ra y được lấy từ quan sát K: áp dụng giá trị trung bình của các khoản khấu trừ y.  \n",
    "- Bước 4: Dự đoán cuối cùng sẽ là giá trị được tính ở bước 3.  \n",
    "<img src=\"img/KNN-pseudo-code.jpg\" style=\"width: 400px; height = 400px;\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2. Linear_Regression**  \n",
    "\n",
    "Linear_Regression là một phương pháp hồi quy thống kê đơn giản và yên tĩnh được sử dụng để phân tích dự đoán và cho thấy mối quan hệ giữa các biến liên tục. Hồi quy tuyến tính cho thấy mối quan hệ tuyến tính giữa biến độc lập (trục X) và biến phụ thuộc (trục Y), do đó được gọi là hồi quy tuyến tính . Nếu có một biến đầu vào duy nhất (x), hồi quy tuyến tính như vậy được gọi là  hồi quy tuyến tính đơn giản . Và nếu có nhiều hơn một biến đầu vào, hồi quy tuyến tính như vậy được gọi là  hồi quy tuyến tính bội .  \n",
    "\n",
    "Mô hình hồi quy tuyến tính đưa ra một đường thẳng dốc mô tả mối quan hệ giữa các biến.  \n",
    "<img src=\"img/Linear_Regression.png\" style=\"width: 400px; height = 100%;\">  \n",
    "\n",
    "Hồi quy tuyến tính có thể được biểu thị bằng toán học như sau: \n",
    "\n",
    "**y=  β0 +  β1x + ε**  \n",
    "\n",
    "- Y= Biến phụ thuộc  \n",
    "- X= Biến độc lập  \n",
    "- β 0 = điểm chặn của đường thẳng   \n",
    "- β 1  = Hệ số hồi quy tuyến tính (độ dốc của đường)  \n",
    "- ε = lỗi ngẫu nhiên  \n",
    "\n",
    "Đầu ra được thuật toán thu được hoặc dự đoán được gọi là  yˆ .Sự khác biệt giữa giá trị thực tế và giá trị dự đoán là sai số, tức là y -   yˆy^ . Các giá trị khác nhau của y-  yˆy^  (loss function) thu được khi mô hình liên tục cố gắng tìm ra mối quan hệ tốt nhất. Tổng trung bình của tất cả các giá trị hàm mất mát được gọi là hàm chi phí. Thuật toán học máy cố gắng đạt được giá trị tối thiểu của hàm chi phí. **Nói cách khác, nó cố gắng đạt đến mức tối thiểu toàn cầu**.  \n",
    "<img src=\"img/Linear_Regression_Loss.jpg\" style=\"width: 400px; height = 100%;\">  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.3. Ride_Regression**  \n",
    "\n",
    "Bản chất toán học:  \n",
    "Ride_Regression nhằm mục đích giảm thiểu hàm chi phí , với p dự đoán, là:  \n",
    "<img src=\"img/Ride_Regression1.png\" style=\"width: 400px; height = 100%;\">  \n",
    "Hiểu tổng bình phương còn lại (RSS):  \n",
    "Đó là tổng bình phương của sự khác biệt giữa giá trị thực tế và giá trị dự đoán:  \n",
    "<img src=\"img/Ride_Regression2.png\" style=\"width: 400px; height = 100%;\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.4. Lasso_Regression**  \n",
    "\n",
    "Một người họ hàng gần gũi của Ridge là Lasso Regression:  \n",
    "<img src=\"img/Lasso_Regression.png\" style=\"width: 400px; height = 100%;\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.5. Decision_Tree**  \n",
    "\n",
    "Mục tiêu của việc sử dụng Decision_Tree là tạo ra một mô hình đào tạo có thể sử dụng để dự đoán loại hoặc giá trị của biến mục tiêu bằng cách  học các quy tắc quyết định đơn giản  được suy ra từ dữ liệu trước đó (dữ liệu huấn luyện).\n",
    "\n",
    "Hồi quy là khi giá trị đích không có bộ nhãn được xác định trước mà là kết quả bằng số. Vấn đề chính ở đây là dự đoán giá trị mục tiêu mới dựa trên dữ liệu huấn luyện.\n",
    "\n",
    "Kỹ thuật hồi quy bằng Decision_Tree có sự khác biệt chính là phép đo cho sự phân chia. Thay vì sử dụng tạp chất, Decision_Tree sử dụng sai số bình phương trung bình ( MSE ). Các câu hỏi giảm dần MSE cho đến khi đạt mức tối thiểu. Kết quả nút là giá trị mục tiêu trung bình từ tất cả các mẫu trong đó. MSE được tính như thế này:  \n",
    "<img src=\"img/Decision_Tree.png\" style=\"width: 400px; height = 100%;\">  \n",
    "\n",
    "Sau khi khớp, mô hình sẽ hướng dẫn một đối tượng mới đến đúng nhánh và gán giá trị mục tiêu trung bình. Đơn giản và mạnh mẽ. Decision_Tree đã hoàn tất."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.6. Random_Forest**  \n",
    "\n",
    "Random_Forest là một thuật toán học có giám sát . “Forest” mà nó xây dựng là một tập hợp các Decision_Tree , thường được huấn luyện bằng phương pháp đóng bao. Ý tưởng chung của phương pháp đóng bao là sự kết hợp của các mô hình học tập sẽ làm tăng kết quả tổng thể.\n",
    "\n",
    "**Các bước liên quan đến thuật toán Random_Forest với bài toán hồi quy:**  \n",
    "- Bước 1: Trong mô hình Random_Forest, một tập hợp con các điểm dữ liệu và một tập hợp con các đối tượng được chọn để xây dựng từng Decision_Tree. Nói một cách đơn giản, n bản ghi ngẫu nhiên và m tính năng được lấy từ tập dữ liệu có k số bản ghi.  \n",
    "- Bước 2: Decision_Tree riêng lẻ được xây dựng cho từng mẫu.  \n",
    "- Bước 3: Mỗi Decision_Tree sẽ tạo ra một đầu ra.  \n",
    "- Bước 4: Kết quả cuối cùng được xem xét dựa trên tính trung bình để hồi quy tương ứng.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.7. Neural_Network**  \n",
    "\n",
    "Với Neural_Network chúng em sử dụng Multi-layer Perceptron để triển khai mô hình và vì là bài toán hồi quy nên lớp được sử dụng là MLPRegressor.  \n",
    "\n",
    "Lớp MLPRegressor triển khai một perceptron nhiều lớp (MLP) đào tạo bằng cách sử dụng lan truyền ngược mà không có chức năng kích hoạt ở lớp đầu ra, điều này cũng có thể được coi là sử dụng chức năng nhận dạng làm chức năng kích hoạt. Do đó, nó sử dụng sai số bình phương làm hàm mất mát và đầu ra là một tập hợp các giá trị liên tục.  \n",
    "\n",
    "MLP huấn luyện bằng cách sử dụng Stochastic gradient Descent , Adam hoặc L-BFGS . Stochastic gradient Descent (SGD) cập nhật các tham số bằng cách sử dụng độ dốc của hàm mất mát đối với tham số cần điều chỉnh, tức là:  \n",
    "<img src=\"img/Neural_Network.png\" style=\"width: 100%; height = 100%;\">  \n",
    "- &#414; (learning rate): tốc độ học kiểm soát kích thước bước trong tìm kiếm không gian tham số.  \n",
    "- Loss: là hàm mất mát được sử dụng cho mạng.  \n",
    "\n",
    "Stochastic gradient descent (thường được viết tắt là SGD ) là một phương pháp lặp để tối ưu hóa hàm mục tiêu với các thuộc tính độ mịn phù hợp. **Phương pháp lặp** là:  \n",
    "<img src=\"img/Neural_Network1.png\" style=\"width: 400px; height = 100%;\">  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Thực nghiệm, kết quả, và thảo luận (experiments, results, and discussions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.1. Giới thiệu chung**  \n",
    "\n",
    "- Thực nghiệm các mô hình nhóm em triển khai hai phương pháp là hold out và cross validation.  \n",
    "<img src=\"img/holdout_model_selection.JPG\" style=\"width: 400px; height = 100%;\">\n",
    "<img src=\"img/cross_val.png\" style=\"width: 400px; height = 100%;\">  \n",
    "- Với hold out dữ liệu sẽ được chia theo tỉ lệ 80/20 và tập train chia tiếp với tỉ lệ 75/25. Với cross validation dữ liệu sẽ được chia tỉ lệ 80/20 và triển khai với 10 tập fold.  \n",
    "\n",
    "- Với đề tài là dự đoán giá cổ phiếu, biến đầu ra sẽ là giá đóng cửa là một biến liên tục, nên đây là bài toán hồi quy. Vì vậy độ đo để đánh giá mô hình là mean square error(MSE)  \n",
    "<img src=\"img/MSE.png\" style=\"width: 400px; height = 100%;\">  \n",
    "- MSE sẽ được tính bằng trung bình tổng các bình phương sai số giữa giá trị dự đoán và thực tế."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.2. Siêu tham số (hyper-parameters)**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.1. K_NN**  \n",
    "\n",
    "Siêu tham số cho thuật toán K_NN là n_neighbors.\n",
    "\n",
    "- Với phương pháp hold out n_neighbors = 3. Nhóm em đã triển khai mô hình với giá trị n_neighbors trên khoảng [1,2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] và tính MSE cho mỗi siêu tham số áp dụng với mô hình với k = 1 mô hình cho giá trị MSE trên tập train rất thấp còn tập test ngược lại nên mô hình đang bị over fitting. Với giá trị k về sau thì MSE tập train tăng cao nên mô hình bị under fitting. Vậy k = 3 cho kết quả tốt nhất.  \n",
    "<img src=\"img/MSE_KNN_Holdout.png\" style=\"width: 400px; height = 100%;\">  \n",
    "\n",
    "- Với phương pháp cross validation n_neighbors = 6. Nhóm em tiếp tục áp dụng với khoảng giá trị trên và chọn ra k có MSE trên tập validation nhỏ nhất  \n",
    "<img src=\"img/KNN_Cross.png\" style=\"width: 400px; height = 100%;\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.2. Linear_Regression**  \n",
    "\n",
    "- Đây là mô hình nhóm em không sử dụng siêu tham số mà sẽ xem kết quả tuyến tính của output dựa trên các input khác nhau:  \n",
    "<img src=\"img/linear1.png\" style=\"width: 400px; height = 100%;\">\n",
    "<img src=\"img/Linear2.png\" style=\"width: 400px; height = 100%;\">  \n",
    "<img src=\"img/linear3.png\" style=\"width: 400px; height = 100%;\">\n",
    "<img src=\"img/linear4.png\" style=\"width: 400px; height = 100%;\">  \n",
    "- Với thuộc tính volume cho kết quả không tốt như các cột còn lại. Cuối cùng mô hình này nhóm em sẽ sử dụng input là các thuộc tính trừ cột volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.3. Ridge_Regression**  \n",
    "\n",
    "- mô hình sử dụng siêu tham số alpha điều chỉnh độ mạnh của regularization (chống overfitting). Ridge sử dụng L2 regularization. Nó thêm một hình phạt tương ứng với bình phương các hệ số (coefficients) vào hàm mất mát.  \n",
    "- Lúc đầu nhóm khảo sát trên khoảng giá trị rất rộng thì thấy phần lớn kết quả của mô hình không có biết đổi gì. Cuối cùng nhóm tìm được khoảng giá trị làm cho kết quả biến đổi và chọn ra giá trị có MSE tập validation nhỏ nhất.  \n",
    "\n",
    "alpha:   100.0 | train mse: 647788.24 | val mse: 110262.69 | test mse: 112926.04  \n",
    "alpha:  1000.0 | train mse: 647788.24 | val mse: 110262.55 | test mse: 112925.82  \n",
    "alpha: 10000.0 | train mse: 647788.24 | val mse: 110261.19 | test mse: 112923.54  \n",
    "alpha: 100000.0 | train mse: 647788.31 | val mse: 110247.66 | test mse: 112900.82  \n",
    "alpha: 1000000.0 | train mse: 647795.08 | val mse: 110119.27 | test mse: 112681.63  \n",
    "alpha: 10000000.0 | train mse: 648396.74 | val mse: 109448.23 | test mse: 111199.6  \n",
    "alpha: 100000000.0 | train mse: 672732.9 | val mse: 125720.63 | test mse: 123616.63  \n",
    "alpha: 1000000000.0 | train mse: 771073.99 | val mse: 211061.79 | test mse: 200687.85  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.4. Lasso_Regression**  \n",
    "\n",
    "- Tương tự như trong Ridge, alpha được sử dụng là siêu tham số điều chỉnh độ mạnh của regularization (chống overfitting). Lasso sử dụng L1 regularization. Nó thêm tổng trị tuyệt đối (sum of absolute values) các hệ số vào hàm mất mát thay vì bình phương các hệ số.  \n",
    "- Dựa vào kết quả vẫn chọn ra alpha có MSE tập validation nhỏ nhất  \n",
    "\n",
    "alpha:     0.0 | train mse: 686273.2 | val mse: 145142.32 | test mse: 150304.66  \n",
    "alpha:   100.0 | train mse: 686270.1 | val mse: 145131.73 | test mse: 150284.43  \n",
    "alpha:  1000.0 | train mse: 686262.13 | val mse: 145054.36 | test mse: 150123.14  \n",
    "alpha: 10000.0 | train mse: 687863.13 | val mse: 145816.02 | test mse: 150256.11  \n",
    "alpha: 100000.0 | train mse: 722160.76 | val mse: 174472.55 | test mse: 176318.83  \n",
    "alpha: 1000000.0 | train mse: 735768.53 | val mse: 202005.45 | test mse: 199586.06  \n",
    "alpha: 10000000.0 | train mse: 1531765.37 | val mse: 1131689.5 | test mse: 1079342.09  \n",
    "alpha: 100000000.0 | train mse: 77352503.71 | val mse: 78582275.0 | test mse: 80964792.36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.5. Decision_Tree**  \n",
    "\n",
    "- Siêu tham số sử dụng cho decision tree là max_depth điều khiển độ sâu tối đa của cây quyết định (decision tree).  \n",
    "- Khảo sát trên một miền giá trị thấy rằng độ sâu càng tăng mô hình cho kết quả càng tốt. Vậy nên giá trị tốt nhất sẽ được chọn ở miền giá trị tốt và có MSE trên tập validation tốt nhất.  \n",
    "- Phương pháp hold out best_max_depth = 7. Cross validation chọn best_max_depth = 10  \n",
    " <img src=\"img/decision_tree_MSE.png\" style=\"width: 400px; height = 100%;\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.6. RandomForest**  \n",
    "\n",
    "- Cũng tương tự như decision tree, siêu tham số được sử dụng là max_depth để điều khiển độ sâu tối đa của mỗi decision tree. Cũng được triển khai tương tự\n",
    "- Kết quả cho thấy MSE vẫn giảm nhưng hai tập test và validation dừng lại ở một mức độ còn xa với train nên giá trị tốt nhất sẽ được chọn ở miền giữa trước khi dừng lại và có MSE validation nhỏ nhất    \n",
    "- Phương pháp hold out best_max_depth = 10. Cross validation chọn best_max_depth = 12  \n",
    " <img src=\"img/randomForest_MSE.png\" style=\"width: 400px; height = 100%;\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.7. neural_network**  \n",
    "\n",
    "- Siêu tham số được sử dụng là alpha, đây là siêu tham số điều chỉnh độ mạnh của regularization (chống overfitting) cho mô hình neural network.  \n",
    "- MLPRegressor sử dụng L2 regularization để tránh overfitting. Nó thêm hình phạt dưới dạng bình phương trọng số (weights) vào hàm mất mát.  \n",
    "- Vì kết quả cho không tốt, MSE tập train luôn cao trên khoảng khảo sát nên giá trị siêu tham số sẽ được chọn ở MSE tập validation nhỏ nhất\n",
    "- Phương pháp hold out chọn alpha = 0.005. Cross validation chọn alpha = 0.004  \n",
    "<img src=\"img/neural_network_MSE.png\" style=\"width: 400px; height = 100%;\">  \n",
    "- Ngoài ra siêu tham số solver = \"lbfgs\" sẽ được sử dụng vì đã giúp cải thiện được rất nhiều. Thuật toán L-BFGS (Limited-memory Broyden–Fletcher–Goldfarb–Shanno) là một thuật toán tối ưu hiệu quả để tìm cực tiểu của hàm mất mát. Hội tụ nhanh hơn so với các thuật toán khác giúp quá trình huấn luyện nhanh chóng và hiệu quả hơn. Nhưng đồng thời phải tăng giá trị siêu tham số max_iter lên từ đó mất nhiều thời gian tính toán hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.3. Kết quả**  \n",
    "\n",
    "<img src=\"img/KetQuaHoldout.png\" style=\"width: 400px; height = 100%;\">\n",
    "<img src=\"img/KetQuaCrossValidation.png\" style=\"width: 400px; height = 100%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sau khi chọn được các siêu tham số, nhóm tiến hành áp dụng mô hình với dữ liệu tổng thể ban đầu. Cho ra kết quả như trên.  \n",
    "- Từ kết quả có thể thấy rằng mô hình K_NN cho kết quả tốt, MSE không cao và tương đồng trên cả hai tập.  \n",
    "- Với mô hình Linear_Regression, Ridge_Regression, Lasso_Regression, Neural_network, kết quả MSE trên tập train quá cao cũng như cao hơn nhiều so với MSE trên tập test. Mô hình đang bị underfitting.\n",
    "- Với mô hình Decision_Tree và Random_Forest, kết quả với phương pháp hold out cho tốt hơn, MSE thấp và gần nhau hơn.\n",
    "Còn triển khai bằng phương pháp Cross validation cho thấy mặc dù MSE hai tập thấp nhưng MSE trên tập train thấp hơn đáng kể so với MSE trên tập test. Nên với phương pháp hold out mô hình ổn còn cross validation cho mô hình overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Kết luận (conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vậy là nhóm em đã triển khai được bảy mô hình K_NN, Linear_Regression, Ridge_Regression, Lasso_Regression, Decision_tree, Random_Forest và neural_network. Với hai phương pháp cho mỗi mô hình là hold out và cross validation.  \n",
    "- Ta đã thấy được thuật toán với hiệu suất cao đó là K_NN với cả hai phương pháp hold out và cross validation.  \n",
    "- Ngoài ra thuật toán Decision_tree và Random_Forest triển khai bằng hold out cũng cho hiệu suất khả quan.  \n",
    "- Như thuật toán K_NN cho hiệu suất cao có thể là do độ đơn giản của mô hình kèm với độ biến thiên của dữ liệu không quá cao nên triển khai dễ dàng và kết quả cũng dễ dàng để khớp với dữ liệu.  \n",
    "- Decision tree cũng tốt vì sự đơn giản của mô hình, dễ giải thích, huấn luyện và dự đoán nhanh.  \n",
    "- Random forest dựa trên decision tree nên vẫn giữ tính đơn giản, dễ giải thích, các cây quyết định độc lập, có thể huấn luyện song song dễ dàng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Đóng góp (contributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"text-align: center;\">\n",
    "  <tr>\n",
    "    <th>Nguyễn Đức Anh</th>\n",
    "    <th>Lưu Hoàng Phúc</th>\n",
    "    <th>Hồ Lê Tấn Lợi</th>\n",
    "    <th>Đặng Tuấn Duẫn</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td colspan=\"4\" >Chọn đề tài</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Quản lý đồ án</td>\n",
    "    <td colspan=\"3\" >Tìm dữ liệu</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Phân chia công việc</td>\n",
    "    <td colspan=\"2\">Soạn nội dung proposal</td>\n",
    "    <td>Làm file proposal</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>làm pptx milestone</td>\n",
    "    <td colspan=\"2\">Soạn nội dung milestone</td>\n",
    "    <td>làm pptx milestone</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Quay video</td>\n",
    "    <td colspan=\"3\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Random Forest</td>\n",
    "    <td>k_NN</td>\n",
    "    <td>Decision_Tree</td>\n",
    "    <td>Ride Regression</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Neural Network</td>\n",
    "    <td>Linear Regression</td>\n",
    "    <td></td>\n",
    "    <td>Lasso Regression</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td colspan=\"2\">Soạn nội dung presentation</td>\n",
    "    <td colspan=\"2\">Làm file presentation</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td colspan=\"4\" >Thuyết trình presentation</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td colspan=\"3\">Làm report</td>\n",
    "    <td >Tổng hợp file</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Tham khảo (references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Aymane Hachcham, The KNN Algorithm – Explanation, Opportunities, Limitations, neptune.ai, 2023  \n",
    "2. Arvind T N, Ridge Regression in AI and Machine Learning: A Comprehensive Deep Dive, Linked in, 2023  \n",
    "3. Devashree Madhugiri, Linear Regression in Machine Learning: A Comprehensive Guide, knowledgehut, 2023   \n",
    "4. Explorium, The Complete Guide to Decision Tree Analysis, Explorium, 2023  \n",
    "5. Sruthi E R, Understand Random Forest Algorithms With Examples (Updated 2024), Analytics Vidhya, 2023  \n",
    "6. Scikit-learn, Neural network models (supervised), 2007  \n",
    "7. numpy, pandas, matplotlib, sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
